{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlorianSong/MResAMS_DataAnalytics/blob/main/Workshop2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "mpl.rc('axes', labelsize = 14)\n",
    "mpl.rc('xtick', labelsize = 12)\n",
    "mpl.rc('ytick', labelsize = 12)\n",
    "\n",
    "\n",
    "# all the functions from sklearn needed for this workshop\n",
    "import sklearn\n",
    "from sklearn.datasets import make_moons, make_circles, load_iris, load_wine\n",
    "from sklearn.svm import LinearSVC, SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-class challenge 1\n",
    "- Below, you will find a line loading another inbuilt dataset from `sklearn`: the `wine` data. This data set is the result of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "\n",
    "- Use code from above to fit a Decision Tree to this data, to determine which of the 13 measured predictors are to be used to classify some wine into one of the three categories. *Make sure to use `train_test_split` to split your data into training and test datasets!* \n",
    "\n",
    "- What difference do the different regularisation parameters make?\n",
    "\n",
    "- What's your prediction success rate? What does this say about the data? Run your Decision Tree a few times to see how the random number generator plays a big role! \n",
    "\n",
    "- *Hint:* plotting the decision tree may or may not end up a little confusing and unclear. You can use `print(export_tree(..., feature_names=...))` to get a text formatted version instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "wine = sklearn.datasets.load_wine()\n",
    "#print(wine.DESCR) # Uncomment to get detailed dataset information\n",
    "print(wine['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_9 <= 3.82\n",
      "|   |--- feature_12 <= 1010.00\n",
      "|   |   |--- feature_2 <= 3.07\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- feature_2 >  3.07\n",
      "|   |   |   |--- class: 0\n",
      "|   |--- feature_12 >  1010.00\n",
      "|   |   |--- class: 0\n",
      "|--- feature_9 >  3.82\n",
      "|   |--- feature_6 <= 1.40\n",
      "|   |   |--- class: 2\n",
      "|   |--- feature_6 >  1.40\n",
      "|   |   |--- feature_12 <= 724.50\n",
      "|   |   |   |--- feature_0 <= 13.14\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_0 >  13.14\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_12 >  724.50\n",
      "|   |   |   |--- class: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1, 2, 3, code!\n",
    "X_wine, y_wine = load_wine(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print(export_text(tree_clf))\n",
    "\n",
    "np.sum(tree_clf.predict(X_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-class challenge 2\n",
    "\n",
    "- Remember the wine dataset? The Decision Tree earlier on worked ok, but the prediction success rate varied wildly and wasn't all that good either... \n",
    "- What about fitting a Random Forest? *Again, don't forget to split training and test!*\n",
    "- Which of the features were the most important in the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n",
      "0.14 alcohol\n",
      "0.03 malic_acid\n",
      "0.01 ash\n",
      "0.03 alcalinity_of_ash\n",
      "0.02 magnesium\n",
      "0.05 total_phenols\n",
      "0.15 flavanoids\n",
      "0.01 nonflavanoid_phenols\n",
      "0.03 proanthocyanins\n",
      "0.15 color_intensity\n",
      "0.1 hue\n",
      "0.1 od280/od315_of_diluted_wines\n",
      "0.17 proline\n"
     ]
    }
   ],
   "source": [
    "# Let's start by loading the wine dataset\n",
    "X_wine, y_wine = load_wine(return_X_y = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wine, y_wine)\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500)\n",
    "\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred_rf, y_test))\n",
    "\n",
    "for name, score in zip(load_wine()['feature_names'], rnd_clf.feature_importances_):\n",
    "    print(round(score,2), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
