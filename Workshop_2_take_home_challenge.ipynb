{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlorianSong/MResAMS_DataAnalytics/blob/main/Workshop2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analytics 2022\n",
    "### Workshop 2 &ndash; Machine Learning Classics: Supervised Learning &ndash; 2rd November 2022\n",
    "##### Taught by: Nan Wu, Wilson Wu, Florian Song, Linden Schrecker, Annabel Basford, Sophia Yaliraki\n",
    "\n",
    "Much of today's workshop was taken from https://github.com/ageron/handson-ml2/ which in turn is based on the second edition of an O'Reilly book [Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/) by Aurélien Geron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= '0.20'\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "mpl.rc('axes', labelsize = 14)\n",
    "mpl.rc('xtick', labelsize = 12)\n",
    "mpl.rc('ytick', labelsize = 12)\n",
    "\n",
    "\n",
    "# all the functions from sklearn needed for this workshop\n",
    "import sklearn\n",
    "from sklearn.datasets import make_moons, make_circles, load_iris, load_wine\n",
    "from sklearn.svm import LinearSVC, SVC, SVR\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take-home challenge: Classifying biodegradability\n",
    "\n",
    "- This week, we will look at the QSAR biodegradation dataset available [here](https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation) which can also be found in the datasets folder in this workspace. This dataset contains 41 molecular descriptors and 1 experimental class: ready biodegradable (RB) and not ready biodegradable (NRB). As you can tell, this dataset lends itself nicely to using decision trees and random forests. \n",
    "- Firstly, have a look at the data webpage linked above. Familiarise yourself with all the descriptors and think about which ones may have more predicting power over others. \n",
    "- Using a package of your choice (`csv` or `pandas` or something else), read in the dataset and encode the class variable as integers. The direct link to the dataset is here (this works directly with pandas.read_csv!): `https://archive.ics.uci.edu/ml/machine-learning-databases/00254/biodeg.csv` \n",
    "- Fit a decision tree (*training/test*!). What's the prediction success rate? Find out the spread of the success rate (mean, variance).\n",
    "- Fit a random forest. Does this improve things? \n",
    "- Can you tune the parameters to get an even better prediction rate? \n",
    "- Which parameters are more important than others? What happens when you train on a subset of parameters? Play around with this to see what happens. \n",
    "- *Bonus:* In the associated paper, the authors used - amongst other methods - Support Vector Machines fitted to the data. Read to the extra material on SVMs and try to fit an SVM to this data. How does it perform compared to the random forest?  \n",
    "- *Bonus 2:* Implement a simple stacking ensemble method with your choice of predictors. Again, can you improve your high-score?\n",
    "- *Bonus 3:* Using at least 5-fold cross-validation (https://scikit-learn.org/stable/modules/cross_validation.html) to obtain a range of predictions, report your average precision for your best model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and encoding the outcome variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "biodeg = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00254/biodeg.csv', \n",
    "                     sep = ';', header = None)\n",
    "biodeg = biodeg.to_numpy()\n",
    "\n",
    "X_biodeg = biodeg[:, :-1].astype(float)\n",
    "y_biodeg = biodeg[:, -1].astype(str)\n",
    "\n",
    "y_biodeg = np.array([0 if i == 'NRB' else 1 for i in y_biodeg]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803030303030303"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a decision tree and reporting a success score\n",
    "\n",
    "X_biodeg_train, X_biodeg_test, y_biodeg_train, y_biodeg_test = train_test_split(X_biodeg, y_biodeg)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_biodeg_train, y_biodeg_train)\n",
    "decision_tree.score(X_biodeg_test, y_biodeg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809719696969697 0.022391216209953463\n"
     ]
    }
   ],
   "source": [
    "# Record the scores of 500 Decision trees and get the mean and standard deviation of all scores\n",
    "\n",
    "scores = []\n",
    "for i in range(500):\n",
    "    X_biodeg_train, X_biodeg_test, y_biodeg_train, y_biodeg_test = train_test_split(X_biodeg, y_biodeg)\n",
    "    scores += [DecisionTreeClassifier().fit(X_biodeg_train, y_biodeg_train).score(X_biodeg_test, y_biodeg_test)]\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484848484848485"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a random forest to the data\n",
    "\n",
    "X_biodeg_train, X_biodeg_test, y_biodeg_train, y_biodeg_test = train_test_split(X_biodeg, y_biodeg)\n",
    "random_forest = RandomForestClassifier(n_estimators = 500)\n",
    "random_forest.fit(X_biodeg_train, y_biodeg_train)\n",
    "    \n",
    "random_forest.score(X_biodeg_test, y_biodeg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8686363636363638 0.017282692500160266\n"
     ]
    }
   ],
   "source": [
    "# Run 50 random forests, each with 100 trees, to get the average score and std deviation\n",
    "\n",
    "scores = []\n",
    "for i in range(50):\n",
    "    X_biodeg_train, X_biodeg_test, y_biodeg_train, y_biodeg_test = train_test_split(X_biodeg, y_biodeg)\n",
    "    scores += [RandomForestClassifier(n_estimators = 100).fit(X_biodeg_train, y_biodeg_train).score(X_biodeg_test, y_biodeg_test)]\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35th feature: 0.092 SpMax_B(m)\n",
      " 0th feature: 0.074 SpMax_L\n",
      "21th feature: 0.064 SpPosA_B(p)\n",
      "38th feature: 0.059 SM6_B(m)\n",
      "26th feature: 0.056 SpMax_A\n",
      "14th feature: 0.041 SM6_L\n",
      "12th feature: 0.035 HyWi_B(m)\n",
      "11th feature: 0.035 SdssC\n",
      "29th feature: 0.032 SdO\n",
      "36th feature: 0.032 Psi_i_A\n",
      "15th feature: 0.031 F03[C-O]\n",
      "17th feature: 0.031 Mi\n",
      " 1th feature:  0.03 J_Dz(e)\n",
      " 7th feature: 0.029 C%\n",
      "13th feature: 0.029 LOC\n",
      "33th feature: 0.028 F02[C-N]\n",
      "30th feature: 0.028 TI2_L\n",
      " 9th feature: 0.027 nO\n",
      "37th feature: 0.027 nN\n",
      "16th feature: 0.027 Me\n",
      " 2th feature: 0.023 nHM\n",
      "27th feature:  0.02 Psi_i_1d\n",
      "10th feature: 0.019 F03[C-N]\n",
      " 4th feature: 0.018 F04[C-N]\n",
      " 8th feature: 0.016 nCp\n",
      " 5th feature: 0.015 NssssC\n",
      " 6th feature: 0.015 nCb-\n",
      "32th feature: 0.013 C-026\n",
      "40th feature: 0.012 nX\n",
      "34th feature: 0.012 nHDon\n",
      "39th feature: 0.009 nArCOOR\n",
      "22th feature: 0.008 nCIR\n",
      "31th feature: 0.004 nCrt\n",
      "24th feature: 0.003 B03[C-Cl]\n",
      " 3th feature: 0.002 F01[N-N]\n",
      "19th feature: 0.001 nArNO2\n",
      "18th feature: 0.001 nN-N\n",
      "25th feature: 0.001 N-073\n",
      "23th feature:   0.0 B01[C-Br]\n",
      "28th feature:   0.0 B04[C-Br]\n",
      "20th feature:   0.0 nCRX3\n"
     ]
    }
   ],
   "source": [
    "# Get information about the importance of each predictor variable\n",
    "# Header names were taken from the paper (downloadable excel file)\n",
    "\n",
    "header_names = np.array( ['SpMax_L', 'J_Dz(e)', 'nHM', 'F01[N-N]', 'F04[C-N]', 'NssssC', 'nCb-', 'C%', 'nCp', 'nO', 'F03[C-N]', 'SdssC', 'HyWi_B(m)', 'LOC', 'SM6_L', 'F03[C-O]', 'Me', 'Mi', 'nN-N', 'nArNO2', 'nCRX3', 'SpPosA_B(p)', 'nCIR', 'B01[C-Br]', 'B03[C-Cl]', 'N-073', 'SpMax_A', 'Psi_i_1d', 'B04[C-Br]', 'SdO', 'TI2_L', 'nCrt', 'C-026', 'F02[C-N]', 'nHDon', 'SpMax_B(m)', 'Psi_i_A', 'nN', 'SM6_B(m)', 'nArCOOR', 'nX'])\n",
    "X_biodeg_train, X_biodeg_test, y_biodeg_train, y_biodeg_test = train_test_split(X_biodeg, y_biodeg)\n",
    "random_forest = RandomForestClassifier(n_estimators = 1000).fit(X_biodeg_train, y_biodeg_train)\n",
    "ordered = random_forest.feature_importances_.argsort()[::-1]\n",
    "for (i, name, score) in zip(ordered, header_names[ordered], random_forest.feature_importances_[ordered]):\n",
    "    print('{}th feature:'.format(str(i).rjust(2)) , str(round(score,3)).rjust(5),  name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top n predictors and train only with those\n",
    "\n",
    "top_predictors = random_forest.feature_importances_.argsort()[-17:][::-1]\n",
    "X_biodeg_new = X_biodeg[:, top_predictors]\n",
    "\n",
    "X_biodeg_train_new, X_biodeg_test_new, y_biodeg_train_new, y_biodeg_test_new = train_test_split(X_biodeg_new, y_biodeg)\n",
    "\n",
    "new_random_forest = RandomForestClassifier(n_estimators = 500)\n",
    "new_random_forest.fit(X_biodeg_train_new, y_biodeg_train_new)\n",
    "\n",
    "new_random_forest.score(X_biodeg_test_new, y_biodeg_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522727272727273"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus 1: Fitting an SVM\n",
    "\n",
    "svm_rbf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm_clf', SVC(kernel = 'rbf'))\n",
    "    ])\n",
    "\n",
    "svm_rbf.fit(X_biodeg_train, y_biodeg_train)\n",
    "\n",
    "y_biodeg_pred_svm = svm_rbf.predict(X_biodeg_test)\n",
    "accuracy_score(y_biodeg_pred_svm, y_biodeg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1055, 41) (593, 41) (198, 41) (264, 41)\n",
      "Training the RandomForestClassifier()\n",
      "Training the ExtraTreesClassifier()\n",
      "Training the Pipeline(steps=[('scaler', StandardScaler()), ('svm_clf', SVC(gamma='auto'))])\n",
      "Training the MLPClassifier(max_iter=1000)\n",
      "Accuracies: [0.8737373737373737, 0.8939393939393939, 0.8686868686868687, 0.8686868686868687]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8787878787878788"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus 2: Stacked ensemble learning (building from scratch)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_biodeg, y_biodeg)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val)\n",
    "print(X_biodeg.shape, X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "random_forest_clf = RandomForestClassifier(n_estimators = 100)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators = 100)\n",
    "svm_clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm_clf', SVC(kernel = 'rbf', gamma = 'auto'))\n",
    "    ])\n",
    "mlp_clf = MLPClassifier(max_iter = 1000)\n",
    "\n",
    "\n",
    "estimators = [random_forest_clf, extra_trees_clf, svm_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print('Training the', estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "print('Accuracies:', [estimator.score(X_val, y_val) for estimator in estimators])\n",
    "\n",
    "X_val_predictions = np.empty((len(X_val), len(estimators)), dtype = np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_val_predictions[:, index] = estimator.predict(X_val)\n",
    "        \n",
    "        \n",
    "rnd_forest_blender = RandomForestClassifier(n_estimators = 200, oob_score = True)\n",
    "rnd_forest_blender.fit(X_val_predictions, y_val)\n",
    "\n",
    "\n",
    "X_test_predictions = np.empty((len(X_test), len(estimators)), dtype = np.float32)\n",
    "\n",
    "for index, estimator in enumerate(estimators):\n",
    "    X_test_predictions[:, index] = estimator.predict(X_test)\n",
    "    \n",
    "y_pred = rnd_forest_blender.predict(X_test_predictions)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;etr&#x27;, ExtraTreesClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                                (&#x27;svm_clf&#x27;,\n",
       "                                                 SVC(gamma=&#x27;auto&#x27;))])),\n",
       "                               (&#x27;mlp&#x27;,\n",
       "                                MLPClassifier(max_iter=1000, random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
       "                                                          oob_score=True,\n",
       "                                                          random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                               (&#x27;etr&#x27;, ExtraTreesClassifier(random_state=42)),\n",
       "                               (&#x27;svm&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                                (&#x27;svm_clf&#x27;,\n",
       "                                                 SVC(gamma=&#x27;auto&#x27;))])),\n",
       "                               (&#x27;mlp&#x27;,\n",
       "                                MLPClassifier(max_iter=1000, random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
       "                                                          oob_score=True,\n",
       "                                                          random_state=42))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>etr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(gamma=&#x27;auto&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>mlp</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000, random_state=42)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, oob_score=True, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n",
       "                               ('etr', ExtraTreesClassifier(random_state=42)),\n",
       "                               ('svm',\n",
       "                                Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                                ('svm_clf',\n",
       "                                                 SVC(gamma='auto'))])),\n",
       "                               ('mlp',\n",
       "                                MLPClassifier(max_iter=1000, random_state=42))],\n",
       "                   final_estimator=RandomForestClassifier(n_estimators=200,\n",
       "                                                          oob_score=True,\n",
       "                                                          random_state=42))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonus 2: Stacked ensemble learning (simple stacking)\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators = [\n",
    "        ('rf', RandomForestClassifier(n_estimators = 100, random_state = 42)),\n",
    "        ('etr', ExtraTreesClassifier(n_estimators = 100, random_state = 42)),\n",
    "        ('svm', Pipeline([('scaler', StandardScaler()), ('svm_clf', SVC(kernel = 'rbf', gamma = 'auto'))])),\n",
    "        ('mlp', MLPClassifier(max_iter = 1000, random_state = 42))\n",
    "    ],\n",
    "    final_estimator = RandomForestClassifier(n_estimators = 200, oob_score = True, random_state = 42)\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_biodeg_train, y_biodeg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484848484848485"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_biodeg_pred = stacking_clf.predict(X_biodeg_test)\n",
    "\n",
    "accuracy_score(y_biodeg_test, y_biodeg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors             Accuracy: 0.81 (+/- 0.09)\n",
      "RBF SVM                       Accuracy: 0.87 (+/- 0.08)\n",
      "Decision Tree                 Accuracy: 0.80 (+/- 0.05)\n",
      "Random Forest                 Accuracy: 0.85 (+/- 0.10)\n",
      "Extremely randomized trees    Accuracy: 0.85 (+/- 0.09)\n",
      "Gradient Boost                Accuracy: 0.85 (+/- 0.11)\n",
      "Neural Net                    Accuracy: 0.86 (+/- 0.07)\n",
      "AdaBoost                      Accuracy: 0.85 (+/- 0.11)\n",
      "Naive Bayes                   Accuracy: 0.71 (+/- 0.06)\n",
      "Voting soft (ERT, SVM, NN)    Accuracy: 0.88 (+/- 0.07)\n",
      "Stacking (ERT, SVM, NN)       Accuracy: 0.87 (+/- 0.08)\n"
     ]
    }
   ],
   "source": [
    "# Bonus 3: Compare a range of models to get the best \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = {\n",
    "    'Nearest Neighbors': KNeighborsClassifier(2), \n",
    "    'RBF SVM' : Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm_clf', SVC(kernel = 'rbf', gamma = 'auto'))\n",
    "    ]),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators = 100),\n",
    "    'Extremely randomized trees': ExtraTreesClassifier(n_estimators = 100), \n",
    "    'Gradient Boost': GradientBoostingClassifier(),\n",
    "    'Neural Net': MLPClassifier(max_iter = 1000),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Naive Bayes': GaussianNB(), \n",
    "    'Voting soft (ERT, SVM, NN)': VotingClassifier(estimators = [\n",
    "        ('ERT', ExtraTreesClassifier(n_estimators = 100)), \n",
    "        ('SVM', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', SVC(kernel = 'rbf', gamma = 'auto', probability = True))\n",
    "        ])), \n",
    "        ('NN', MLPClassifier(max_iter=1000)),\n",
    "    ], voting = 'soft'), \n",
    "    'Stacking (ERT, SVM, NN)': StackingClassifier(estimators = [\n",
    "        ('ERT', ExtraTreesClassifier(n_estimators = 100)),\n",
    "        ('SVM', Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svm_clf', SVC(kernel = 'rbf', gamma = 'scale', probability = True))\n",
    "        ])),\n",
    "        ('NN', MLPClassifier(max_iter = 1000))\n",
    "    ], final_estimator = RandomForestClassifier(n_estimators = 500))\n",
    "\n",
    "}\n",
    "for name,estimator in estimators.items():\n",
    "    scores = cross_val_score(estimator, X_biodeg, y_biodeg, cv = 5)\n",
    "    print(name.ljust(30) + 'Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
